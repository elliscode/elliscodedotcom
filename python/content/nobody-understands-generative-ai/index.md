I don't understand generative AI, and I never will, and that's okay with me. Much like I don't understand how atoms work, yet I am made of atoms. Or how my shoes are manufactured, yet I wear them. I just know they work, and that's all I need.

With all things I dont understand, usually *somebody* does, however I can't say that about generative AI. And that fact has always bothered me. Even those that "built" generative AI do not understand how it works.

Generative AI uses something called "parameters", sometimes referred to as "weights", to dictate the probabilities of what token it will spit out next. When a generative AI model is "trained", it is fed data that trains these parameters, and this training dictates what these parameters will be for the rest of its existence. The most interesting part to me is that *nobody* knows what these parameters do. In a model with a trillion parameters, you can't isolate one and say "this parameter controls putting question marks at the end of questions", or "this parameter defines how sycophantic the responses will be", because all trillion of these parameters work in tandem to shape what the output will be.

Sure, the engineers understand that if they train a model on say, a the entirety of Wikipedia, that the model will respond similarly to Wikipedia content. But nobody, not even the engineers who trained it, understand at the individual parameter level what they control.  They can't take a model apart and say "leave in all the knowledge about chemistry but take out all the knowledge about illegal drug manufacturing", because the parameters don't work like that. All they can do is suggest that the model not do bad things by adding a "system prompt" and strongly wording the rules it must follow. 


